{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers transformers peft torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPyAJYBwKi8Z",
        "outputId": "f5a4563d-8309-4267-8d55-cd876870f8f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.32.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "from peft import AdaLoraConfig, get_peft_model\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import json\n",
        "import torch\n",
        "\n",
        "class TaskSpecificFineTuning:\n",
        "    def __init__(self, model_path=\"google/flan-t5-small\"):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        self.model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
        "        self.configure_peft_adapter()\n",
        "\n",
        "    def configure_peft_adapter(self, verbose=True) -> None:\n",
        "        \"\"\"Configure the PEFT adapter.\"\"\"\n",
        "        self.adapter_config = AdaLoraConfig(target_r=16)\n",
        "        self.model = get_peft_model(self.model, self.adapter_config)\n",
        "        if verbose:\n",
        "            self.model.print_trainable_parameters()\n",
        "\n",
        "    def ask_question(self, question, context, device=\"cpu\"):\n",
        "        \"\"\"Tokenize the input and predict the answer.\"\"\"\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            question, context, add_special_tokens=True, return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Adjustments for device placement\n",
        "        device = torch.device(device)\n",
        "        self.model.to(device)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        # Get model predictions\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
        "\n",
        "        # Get the start and end positions\n",
        "        answer_start_scores = outputs.start_logits\n",
        "        answer_end_scores = outputs.end_logits\n",
        "\n",
        "        # Find the tokens with the highest `start` and `end` scores\n",
        "        answer_start = torch.argmax(answer_start_scores)\n",
        "        answer_end = torch.argmax(answer_end_scores) + 1\n",
        "\n",
        "        # Convert the tokens to the answer string\n",
        "        answer = self.tokenizer.convert_tokens_to_string(\n",
        "            self.tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end])\n",
        "        )\n",
        "        return answer\n",
        "\n",
        "\n",
        "class StylesprintDataset(Dataset):\n",
        "    def __init__(self, tokenizer, data):\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        question, answer = self.data[idx][\"question\"], self.data[idx][\"answer\"]\n",
        "\n",
        "        # Tokenize the pair\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            question,\n",
        "            answer,\n",
        "            add_special_tokens=True,\n",
        "            max_length=512,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_offsets_mapping=True,\n",
        "        )\n",
        "        input_ids = encoding[\"input_ids\"]\n",
        "        attention_mask = encoding[\"attention_mask\"]\n",
        "        offset_mapping = encoding[\"offset_mapping\"]\n",
        "\n",
        "        # Initialize start and end positions to None\n",
        "        start_positions = None\n",
        "        end_positions = None\n",
        "\n",
        "        # Find the start and end of the answer in the tokenized sequence\n",
        "        for i, offset in enumerate(offset_mapping):\n",
        "            if (\n",
        "                start_positions is None\n",
        "                and offset[0] == 0\n",
        "                and self.tokenizer.decode([input_ids[i]]).strip() == answer.split()[0]\n",
        "            ):\n",
        "                start_positions = i\n",
        "            if (\n",
        "                offset[1] == len(answer)\n",
        "                and self.tokenizer.decode([input_ids[i]]).strip() == answer.split()[-1]\n",
        "            ):\n",
        "                end_positions = i\n",
        "\n",
        "        # Ensure that start and end positions are set\n",
        "        if start_positions is None or end_positions is None:\n",
        "            start_positions = 0\n",
        "            end_positions = 0\n",
        "\n",
        "        # Return the inputs and positions\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(input_ids),\n",
        "            \"attention_mask\": torch.tensor(attention_mask),\n",
        "            \"start_positions\": torch.tensor(start_positions),\n",
        "            \"end_positions\": torch.tensor(end_positions),\n",
        "        }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    ts = TaskSpecificFineTuning(\"google/flan-t5-base\")\n",
        "\n",
        "    # Create some demo data (replace this with your actual data)\n",
        "    demo_data = [\n",
        "        {\"question\": \"Can I exchange an online purchase?\", \"answer\": \"Yes, within 30 days\"},\n",
        "        {\"question\": \"What's the return policy?\", \"answer\": \"30 days from purchase\"},\n",
        "        # Add more question-answer pairs as needed\n",
        "    ]\n",
        "\n",
        "    # Split the mock dataset into training and evaluation sets (50/50)\n",
        "    train_data = StylesprintDataset(ts.tokenizer, demo_data[: len(demo_data) // 2])\n",
        "    eval_data = StylesprintDataset(ts.tokenizer, demo_data[len(demo_data) // 2 :])\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"/content/drive/MyDrive/stylesprint_qa_results\",\n",
        "        num_train_epochs=20,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=64,\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir=\"/content/drive/MyDrive/stylesprint_qa_logs\",\n",
        "        logging_steps=10,\n",
        "    )\n",
        "\n",
        "    # Initialize the Trainer\n",
        "    trainer = Trainer(\n",
        "        model=ts.model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_data,\n",
        "        eval_dataset=eval_data,\n",
        "    )\n",
        "\n",
        "    # Start training\n",
        "    trainer.train()\n",
        "\n",
        "    # Save the model\n",
        "    ts.model.save_pretrained(\"/content/drive/MyDrive/stylesprint_qa_model\")\n",
        "    ts.tokenizer.save_pretrained(\"/content/drive/MyDrive/stylesprint_qa_model\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    question = \"Can I exchange an online purchase?\"\n",
        "\n",
        "    # Example context (You can use any relevant text)\n",
        "    context = \"\"\"\n",
        "    At Stylesprint, we strive to ensure the utmost satisfaction for all our customers. Our return and exchange policy is crafted to provide you with a seamless and convenient shopping experience. If you're not completely satisfied with your purchase, you can return or exchange your items within 30 days from the date of purchase. To be eligible for a return or exchange, items must be in their original, unworn condition with all tags attached. Footwear returns must include the original shoebox in its original condition. We request that you provide a valid proof of purchase with any return. Refunds will be processed to the original method of payment and may take up to two billing cycles to appear on your credit card statement.\n",
        "    In the case of exchanges, the availability of your desired item will be confirmed upon processing. If the item is not available, we will issue a refund instead. Please note that sale items are only eligible for exchange and not for refunds. Our aim is to make your shopping experience as enjoyable as possible, and our dedicated customer service team is always here to assist you with any concerns or questions you may have regarding our return policy.\n",
        "    \"\"\"\n",
        "\n",
        "    answer = ts.ask_question(\n",
        "        question, context, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    )\n",
        "    print(\"Question:\", question)\n",
        "    print(\"Answer:\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "2wFEh8dmL017",
        "outputId": "64ef0940-b5bd-4201-974b-3a1bd5788a71"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of T5ForQuestionAnswering were not initialized from the model checkpoint at google/flan-t5-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 3,467,232 || all params: 226,372,490 || trainable%: 1.5316\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 04:44, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>6.321200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>6.322800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Can I exchange an online purchase?\n",
            "Answer: a refund instead. Please note that sale items are only eligible for exchange and not for refunds. Our aim is to make your shopping experience as enjoyable as possible, and our dedicated customer service team is always here\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wL7cZt3G3jG8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}